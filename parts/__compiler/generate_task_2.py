
from data.table_a2 import table

import math
import pandas as pd
import numpy as np
from scipy.stats import f as fishers_f
import settings

print(r"""\section{Завдання №2}
Для вибірки із завдання 1. \\
1. Розрахувати лінійний парний коефіцієнт кореляції, перевірити його значущість та знайти інтервал довіри. \\
2. Що можна сказати про тісноту та напрямок зв’язку між ознаками? \\
3. За тими ж даними розрахувати кореляційне відношення, перевірити його значущість та знайти інтервали довіри. \\
4. Порівняти значення коефіцієнта детермінації (див. завдання 1), коефіцієнта кореляції та кореляційного відношення. Надати змістовну інтерпретацію отриманим результатам. Чи можна вважати зв’язок між ознаками близьким до лінійного? 
\subsection{Розв'язання}
\textbf{Лінійний коефіцієнт кореляції.}
\subsubsection{Лінійний парний коефіцієнт кореляції.}
Одним із основних показників взаємозалежності двох випадкових величин є парний коефіцієнт кореляції. Його вперше розглянули Пірсон, Еджворт і Велтон.\\
Парний коефіцієнт кореляції характеризує тісноту і напрямок зв’язку між двома корелюючими ознаками у випадку наявності між ними лінійної залежності.\\
Ці дві ознаки повинні вести себе як двовимірна нормальна випадкова величина.\\
Відзначимо властивості парного коефіцієнта кореляції.
1. Значення коефіцієнта кореляції належить відрізкові [-1; 1]. Якщо $\widehat{r}>0$ , то зв’язок між ознаками x і y прямий (обидві зростають або обидві зменшуються одночасно); якщо ж $\widehat{r}<0$, то зв’язок обернений (якщо одна ознака зростає, то друга спадає і навпаки).\\
2. Якщо випадкові величини x і y статистично незалежні, то $\widehat{r}=0$\\
3. Із того, що $\widehat{r}=0$, випливає лінійна незалежність випадкових величин.\\
4. Якщо $\widehat{r}=1$, то це означає, що між змінними x і y існує функціональний лінійний зв’язок і навпаки: якщо між x і y існує функціональна лінійна залежність, то $\widehat{r}=1$.\\
5. Коефіцієнт кореляції є симетричною функцією змінних x і y : $\widehat{r_{xy}}=\widehat{r_{yx}}$. \\
Визначений співвідношенням (1) вибірковий коефіцієнт кореляції може бути розрахований для довільної двовимірної системи спостережень. Він є вимірником ступеня тісноти лінійного статистичного зв’язку між ознаками. Однак
тільки у випадку спільного нормального розподілу випадкових величин коефіцієнт кореляції r має чітке значення як характеристика ступеня тісноти зв’язку між ними.\\
Крім того, коефіцієнт кореляції разом з середніми і дисперсіями випадкових величин складає ті п’ять параметрів, які дають вичерпні відомості про стохастичну залежність величин, тому що однозначно визначають їх двовимірний закон розподілу.\\
У всіх інших випадках (розподіли x і y відхиляються від нормального, одна з величин не є випадковою і т. д.) коефіцієнт кореляції можна використовувати лише як одну з можливих характеристик ступеня тісноти зв’язку. При цьому, не дивлячись на те, що в загальному випадку поки що не запропоновано характеристики лінійного зв’язку, яка мала б очевидні переваги в порівнянні з r ,його інтерпретація досить часто є ненадійною. Якщо апріорі допускається можливість відхилення від лінійного вигляду залежності, то можна побудувати приклади, коли при r = 0 існує чисто функціональна залежність між ознаками. Тому про величини, для яких r = 0 , кажуть, що вони некорельовані, і тільки після професійного аналізу можна сказати, чи є вони незалежними. І навпаки, з
високого ступеня корельованості величин при великих відхиленнях їх розподілів від нормального ще не виходить їх досить тісна залежність.\\ 
 Використовуючи вибіркові дані прикладу 1, розрахувати парний коефіцієнт кореляції за формулою:\\
\\
$$\displaystyle \hat{r}= \frac{\displaystyle n\sum_{i=1}^{n}x_{i}y_{i}-\sum_{i=1}^{n}x_{i}  \cdot \sum_{i=1}^{n}y_{i}}{\displaystyle \sqrt{\left[n\sum_{i=1}^{n}x^2_{i}- \left(\sum_{i=1}^{n}x_{i} \right )^{2} \right ] \cdot
\left[n\sum_{i=1}^{n}y^2_{i}- \left(\sum_{i=1}^{n}y_{i} \right )^{2} \right ] }}   \;\;\;(7)$$
Відпвідно до формули (7):""")

n = 30
r_hat = (n * sum([x*y for x, y in zip(table.X, table.Y)]) - sum(table.X)*sum(table.Y)) / ((n * sum([x*x for x in table.X]) - sum(table.X)**2)*(n * sum([y*y for y in table.Y]) - sum(table.Y)**2))**(0.5)

print(f"$$\\hat{{r}} = {round(r_hat, 8)} \\approx {round(r_hat, 2)}$$")

print(r"Слід зазначити, що лінійний парний коефіцієнт кореляціє належить відрізку [-1;1]. У нашому випадку $\hat{r}\in [-1;1]$. Відповідно до властивойстей коефіцієнту ми можемо зробити висновок, що зв'язок між \mbox{\boldmath$Y_{1}$,$X_{7}$} ")
if r_hat > 0:
    print(r"є прямий, тобто якщо зростає продуктивність праці, то і зростає фондовіддача, або коли спадає продуктивність праці, спадає і фондовіддача. Але слід провести тест на перевірку значущості коефіцієнта кореляції.\\")
else:
    print(r"є обернений, тобто якщо зростає продуктивність праці, то фондовіддача спадає, або коли спадає продуктивність праці, росте фондовіддача. Але слід провести тест на перевірку значущості коефіцієнта кореляції.\\")

print(r"""\subsubsection{Перевірка значущості коефіцієнта кореляції.}
Після оцінки лінійного коефіцієнта кореляції виникає питання: яку величину вибіркового коефіцієнта кореляції можна вважати достатньою для статистично обґрунтованого висновку про наявність кореляційного зв’язку між
змінними? Надійність статистичних характеристик, в тому числі і $\widehat{r}$, зменшується зі зменшенням об’єму відповідної вибірки, а тому можливі випадки, коли відхилення від нуля отриманої величини вибіркового коефіцієнта кореляції $\widehat{r}$ є статистично незначущим, тобто цілком обумовленим випадковими коливаннями
вибірки, за якою він розрахований. Відповісти на це питання допомагає знання закону ймовірнісного розподілу $\widehat{r}$. У випадку спільної нормальної розподіленості змінних і при достатньо великому об’ємові вибірки n розподіл $\widehat{r}$ можна вважати наближено нормальним з середнім, що дорівнює своєму теоретичному значенню r. Однак необхідно враховувати, що при малих n і значеннях r , близьких до +-1, це наближення є досить грубим. Крім того, при малих n слід брати до уваги, що величина $\widehat{r}$ є зміщеною оцінкою свого теоретичного значення r. \\
Відносно добрий ступінь наближення нормального розподілу при малих значеннях |r| дозволяє отримати простий критерій перевірки гіпотези r = 0, тобто гіпотези про відсутність кореляційного зв’язку між змінними. \\
З'ясуємо питання про значущість коефіцієнта кореляції за тестом:
\begin{enumerate} 
    \item Формулювання гіпотез:
    \newline
    $$H_{A}: r \neq 0,H_{0}: r = 0;$$
    \item Задаємо рівень значущості $\alpha$
    \item Розраховуємо $\displaystyle t_{CT}:t_{CT}= \left| \hat{r} \right| \sqrt{\frac{n-2}{1-\hat{r}^2 }}   \;\;\;(8)$
    \item За таблицею розподілу Ст'юдента визначемо $\displaystyle t_{KP}:t_{KP}= t \left(\frac{\alpha}{2};n-2\right)  \;\;\; (9)$
    \item Якщо $t_{CT}>t_{KP}$, то гіпотеза $H_{0}$ відхиляється з йомовірністю  $(1-\alpha)\cdot 100 \%$
\end{enumerate}
Розрахуємо $t_{CT}$ відповідно до формули (8):
\newline""")

t_st = abs(r_hat) * (28/(1-r_hat**2))**0.5

print(f"$$\\displaystyle t_{{CT}}= \\left| {round(r_hat, 2)} \\right| \\sqrt{{\\frac{{30-2}}{{1-{round(r_hat**2, 4)}}}}} = {round(t_st, 3)}$$")

print(r"""\newline
Розрахуємо $t_{KP}$ відповідно до формули (9) при $\alpha = 0.1$:
\newline
$$\displaystyle t_{KP}= t\left(0.05;28\right) = 2,0484$$""")

if t_st > 2.0484:
    print(r"Зa результатами тесту $t_{CT}>t_{KP}$ тому гіпотеза  $H_{A}$ приймається з ймовірністю 90\%, тобто $r\neq0$, а це означає, що існує залежність між продуктивнiстю працi і фондовіддачею. ")
else:
    print(r"Зa результатами тесту $t_{CT}<t_{KP}$ тому гіпотеза  $H_{0}$ приймається з ймовірністю 90\%, тобто $r=0$, а це означає, що не існує залежності між продуктивнiстю працi і фондовіддачею. ")

print(r"""\newline
\subsubsection{Інтервал довіри для істинного значення коефіцієнта кореляції.}
Для значущого коефіцієнта кореляції r доцільно розрахувати інтервал довіри, який з ймовірністю ($1  − \alpha$)100\% містить в собі істинне значення коефіцієнта кореляції. Для побудови цього інтервалу необхідно знати вибірковий
розподіл коефіцієнта кореляції $r$ , який при $r \neq 0$ несиметричний і дуже повільно із ростом n збігається до нормального розподілу. Тому звертаються до спеціально підібраних функцій від $r$, які при невеликих $n$ збігаються до добре вивчених розподілів. Наприклад, використовують z -перетворення Фішера.  Величина z уже при невеликих n з добрим наближенням наслідує нормальному законові з середнім і дисперсією.\\
Для визначення межі інтервалу довіри для істинного значення коефіцієнта кореляції користуємося тими ж z -таблицями Фішера. Зазначимо, що знаки аргументу і функції співпадають. Цікаво знати, що коефіцієнт кореляції ознак, на які накладаються похибки виміру, завжди менший за абсолютною величиною за коефіцієнт кореляції початкових ознак. Похибки виміру завжди послаблюють кореляційний зв’язок між початковими змінними, і це спотворення тим менше, чим менше відношення дисперсій похибки до дисперсій початкових змінних.\\
Якщо 0 належить інтервалу довіри, то коефіцієнт кореляції незначимо відрізняється від нуля. \\
Коефіцієнт детермінації і парний коефіцієнт кореляції пов’язані між собою співвідношенням: $\displaystyle \widehat{K_d}(y;x) = r_{yx}^2$\\
Визначимо інтервал довіри для істинного значення $r$.
Для цього використаємо $z$-перетворення Фішера:
\newline
$$z_{1}=\frac{1}{2} \ln{\frac{1+\hat{r}}{1-\hat{r}}} - \frac{\hat{r}}{2(n-1)}- \frac{u_{q}}{\sqrt{n-3}} \;\;\;(10),$$
$$z_{2}=\frac{1}{2} \ln{\frac{1+\hat{r}}{1-\hat{r}}} - \frac{\hat{r}}{2(n-1)}+ \frac{u_{q}}{\sqrt{n-3}} \;\;\;(11),$$
де $u_{q}$ – табульовані значення $q$ -квантилей для нормального розподілу, які залежать від $\displaystyle q=1-\frac{\alpha}{2}$
\newline
Використаєто формули (9) та (10) при $\alpha = 0.05$:""")

uq = 1.645

z1 = 0.5 * math.log((1 + r_hat)/(1-r_hat)) - r_hat / (2 * (n-1)) - uq/math.sqrt(n - 3)
z2 = 0.5 * math.log((1 + r_hat)/(1-r_hat)) - r_hat / (2 * (n-1)) + uq/math.sqrt(n - 3)

print(f"$$z_{{1}}=\\frac{{1}}{{2}} \\ln{{\\frac{{1+{round(r_hat, 2)}}}{{1-{round(r_hat, 2)}}}}} - \\frac{{{round(r_hat, 2)}}}{{2(30-1)}} - \\frac{{1.645}}{{\\sqrt{{30-3}}}} = {round(z1, 3)}$$")
print(f"$$z_{{2}}=\\frac{{1}}{{2}} \\ln{{\\frac{{1+{round(r_hat, 2)}}}{{1-{round(r_hat, 2)}}}}} - \\frac{{{round(r_hat, 2)}}}{{2(30-1)}} + \\frac{{1.645}}{{\\sqrt{{30-3}}}} = {round(z2, 3)}$$")

print(r"Скористаємося таблицею $z$-перетворення Фішера і отримаємо межі зміни істинного значення $r$:")
print(f"$${round(np.arctanh(z1), 3)} \\leq r \\leq {round(np.arctanh(z2), 3)}$$")

if np.arctanh(z1) < 0 and 0 < np.arctanh(z2):
    print(r"Так як $0 \in " + f"[{round(np.arctanh(z1), 3)};{round(np.arctanh(z2), 3)}]" + r"$, то коефіцієнт кореляції незначимо відрізняється від нуля.\\")
else:
    print(r"Так як $0 \in " + f"[{round(np.arctanh(z1), 3)};{round(np.arctanh(z2), 3)}]" + r"$, то коефіцієнт кореляції значимо відрізняється від нуля та з ймовірністю 90% знаходиться в проміжку $" + f"[{round(np.arctanh(z1), 3)};{round(np.arctanh(z2), 3)}]" + r"$.\\")

print(r"""Для отримання висновків про практичну значущість в аналізі моделей показникам тісноти статистичного зв’язку дають якісну оцінку за допомогою шкали Чеддока:
\newline
\begin{table}[H]
\centering
\begin{tabular}{ |p{14 em} |p{4 em} |p{4 em} |p{4 em} |p{4 em} |p{6 em} | } 
\hline
\bigcell{l}{\\Показники
тісноти зв’язку}
& 
\bigcell{l}{\\ 0,01-0,3\\}
& 
\bigcell{l}{\\0,3-0,5\\}
& 
\bigcell{l}{\\0,5-0,7\\}
& 
\bigcell{l}{\\0,7-0,9\\}
& 
\bigcell{l}{\\0.9-0,99\\}
\\ 
\hline

\bigcell{l}{\\Характеристика
сили зв’язку}
& 
\bigcell{l}{\\Слабка \\}
& 
\bigcell{l}{\\Помірна\\}
& 
\bigcell{l}{\\Помітна\\}
& 
\bigcell{l}{\\Висока\\}
& 
\bigcell{l}{\\Дуже висока\\}
\\
\hline
\end{tabular}
\end{table}""")

print(r"""\subsubsection{Висновок.}
Можемо зробити висновок, що за храктеристикою зв'язок між \mbox{\boldmath$Y_{"""+ str(settings.task_1_y) +r"""}$,$X_{"""+ str(settings.task_1_x) +r"""}$} є відсутнім.
Також слід зазначити, що співвідношення:
$$\hat{K}_{d} = \hat{r}^2$$ не виконується, що свідчить про нелінійний зв'язок. Користуючись шкалою Чеддока можемо зробити висново, що за характеристикою сили наш зв'язок є """)  

if abs(r_hat) < 0.3:
    print("слабким")
elif abs(r_hat) < 0.5:
    print("помірним")
elif abs(r_hat) < 0.7:
    print("помітним")
elif abs(r_hat) < 0.9:
    print("високим")
else:
    print("дуже високим")


print(r""".
Так як  йде відхилення залежності від лінійного вигляду коефіцієнт кореляції втрачає свій зміст як характеристика ступеня тісноти зв’язку. Тому побудуємо оцінку коефіцієнта детермінації.

\subsubsection{Кореляційне відношення}
Величину $\hat{\rho}_{yx}$ називають кореляційним відношенням залежної змінної y по
незалежній змінній x .\\
Отже, кореляційне відношення $\hat{\rho}_{yx}$ є показником розсіювання точок відносно емпіричної лінії регресії, яка є ламаною, що з’єднує значення yj.\\
Властивості кореляційного відношення
1. Кореляційне відношення належить проміжку $[0,1]$\\
2. Якщо $\hat{\rho}_{yx} = 1$, то це означає наявність однозначної функціональної залежності між y і x , та навпаки.\\
3. Відсутність кореляційного зв’язку між y і x означає, що $\overline{y_j}=\overline{y}$, а тому
$\hat{\rho}_{yx} = 0$. Навпаки, якщо $\hat{\rho}_{yx} = 0$, то $\overline{y_j}=\overline{y}$ і середні yj не залежать від x , тобто лінія регресії паралельна горизонтальній осі.
4. Цікава властивість: $\hat{\rho}_{yx} \ neq \hat{\rho}_{xy}$, тобто на відміну від коефіцієнта кореляції
кореляційне відношення несиметричне по відношенню до досліджуваних змінних.\\
5. Кореляційне відношення $\hat{\rho}_{yx}$ не може бути менше абсолютної величини коефіцієнта кореляції r , який характеризує залежність між тими ж змінними.\\
6. Кореляційне відношення у випадку лінійної залежності між ознаками співпадає з коефіцієнтом кореляції. Це дає можливість використовувати величину $\hat{\rho}_{yx}^2 - \hat{r}^2$ як міру відхилення регресійної залежності від лінійного вигляду.\\\\
Обчислимо кореляційне відношення за формулою:
$$\displaystyle \hat{\rho}_{yx}^2 = \frac{S_{\hat{y}^2}}{S_{y^2}}\;\;\;(12),$$
де:\\
\newline
$\displaystyle S_{\overline{y}}^2$ - оцінка дисперсії $\sigma_{f}^2$ і розраховується за формулою:
$$\displaystyle S_{\overline{y}}^2=\frac{1}{n}\sum_{j=1}^{s}\nu_{j}\left(\overline{y_{j}}-\overline{y}\right)^2\;\;\;(13)$$
$\displaystyle \overline{y}$ - загальне середнє 
\newline
\newline
$\displaystyle \overline{y}_{j}$ - середнє значення ординат точок $j$-го інтервалу групування.
\newline
\newline
$\displaystyle \nu_{j}$ - число вибіркових точок у $j$ -й групі.
\newline
\newline
$\displaystyle S_{y}^2$ - вибіркова дисперсія індивідуальних результатів спостереження $y_{ji}$ навколо
загального середнього $\overline{y}$ 
$$\displaystyle S_{y}^2=\frac{1}{n}\sum_{j=1}^{s}\sum_{i=1}^{\nu_{j}} \left( y_{ji} - \overline{y} \right)^2\;\;\;(14)$$""")

print(r"Значення $\displaystyle \overline{y}_{j}$ беремо з Табл.1 відповідно до формули (2): ")
print(r"\begin{enumerate}")

grouped = table.groupby("X")
for i, (x, group) in enumerate(grouped):
    ym = group["Y"].mean()
    nu = len(group)

    print(f"    \\item $\\displaystyle \\overline{{y}}_{{{i+1}}} = {round(ym, 3)}$,\\;\\;\\;$\\nu_{{{i+1}}} = {nu}$")

s = len(grouped)
ym = table.Y.mean()
s2_yhat = (sum([len(group)*(group['Y'].mean() - ym)**2 for x, group in grouped]))/30
s2_y = sum([sum([(yji - ym)**2 for yji in group['Y']]) for x, group in grouped])/30
p2 = s2_yhat/s2_y

print(r"\end{enumerate}")
print(r"Користуючись результатом, отриманим з формули (3):")
print(f"$$\\displaystyle \\overline{{y}} = {round(ym, 3)}$$")
print(r'ми можемо розрахувати $\displaystyle S_{\overline{y}}^2$ згідно з формулою (12) при $n=30$, $s='+f'{s}$:')
print(f"$$\\displaystyle S_{{\\overline{{y}}}}^2=\\frac{{1}}{{30}}\\sum_{{j=1}}^{{{s}}}\\nu_{{j}}\\left(\\overline{{y_{{j}}}}-{round(ym, 3)}\\right)^2 = {round(s2_yhat, 3)}$$")
print(r"Далі обчислемо $\displaystyle S_{y}^2$ відпоідно до формули (14) при $n=30$, $s="+f'{s}$:')
print(f"$$\\displaystyle S_{{y}}^2=\\frac{{1}}{{30}}\\sum_{{j=1}}^{{{s}}}\\sum_{{i=1}}^{{\\nu_{{j}}}} \\left( y_{{ji}} - {round(ym, 3)} \\right)^2={round(s2_y, 3)}$$")
print(r"Згідно з формулою (12):")
print(f"$$\\displaystyle \\hat{{\\rho}}_{{yx}}^2 = \\frac{{{round(s2_yhat, 3)}}}{{{round(s2_y, 3)}}}={round(p2, 4)}$$")
print(r"тоді:")
print(r"$$\displaystyle \hat{\rho}_{yx} = " + f"{round((s2_yhat/s2_y)**0.5, 3)}$$")

print(r"""\subsubsection{Перевірка значущості кореляційного відношення}
З'ясуємо питання про значущість кореляційного відношення за тестом:
\begin{enumerate} 
    \item Формулювання гіпотез:
    \newline
    $$H_{A}: \rho_{yx} \neq 0,H_{0}: \rho_{yx} = 0;$$
    \item Задаємо рівень значущості $\alpha$
    \item Розраховуємо $\displaystyle F_{CT}:F_{CT}= \frac{\hat{\rho}_{yx}^2}{1-\hat{\rho}_{yx}^2} \cdot \frac{n-s}{s-1} \;\;\;(15)$
    \item За таблицею розподілу Фішера визначемо $\displaystyle F_{KP}:F_{KP}= F \left(\alpha;s-1;n-s\right)  \;\;\; (16)$
    \item Якщо $F_{CT}>F_{KP}$, то гіпотеза $H_{0}$ відхиляється з йомовірністю  $(1-\alpha)\cdot 100 \%$
\end{enumerate}""")

print(r"Розрахуємо $\displaystyle F_{CT}$ відповідно до формули (15) при $n=30$,$s="+f"{s}$:")

fst = p2/(1-p2) * (30 - s)/(s - 1)
fkr = fishers_f.isf(0.1, s-1, n-s)

print(r"$$\displaystyle F_{CT}:F_{CT}= \frac"+f"{{{round(p2, 4)}}}{{1-{round(p2, 4)}}} \\cdot \\frac{{30-{s}}}{{{s}-1}}= {round(fst, 3)}$$")
print(r"Розрахуємо $\displaystyle F_{KP}$ відповідно до формули (16) при $n=30$,$s="+f"{s}"+r"$,$\alpha=0.1$:")
print(f"$$\\displaystyle F_{{KP}}= F \\left(0.1;{s};2\\5\\right)={round(fkr, 3)} $$")
print(r"""Зa результатами тесту $F_{CT}<F_{KP}$, тому гіпотеза  $H_{0}$, тобто $\rho_{yx} = 0$ з йомовірністю 90\%, а це означає, що кореляційне відношення незначимо відрізняється від нуля. 
За властивостями це означає, якщо $\rho_{yx}=0$, то $\overline{y}_{j}=\overline{y}$ і середні $\overline{y}_{j}$ не залежать від $x$ , тобто лінія регресії паралельна горизонтальній осі.
\subsubsection{Інтервал довіри для істиного значення кореляційного відношення}
Для побудови наближених інтервалів довіри для істинного значення
кореляційного відношення скористаємося наступним алгоритмом:
\begin{enumerate} 
    \item Розраховуємо оцінку кореляційного відношення за формулою (12).
    \item За формулою:
    $$\displaystyle \nu_{1}^{*}= \left[\frac{\left(s-1+n\hat{\rho}_{yx}^2\right)^2}{s-1+2n\hat{\rho}_{yx}^2}\right] \;\;\;(17)$$
    розраховуємо допоміжне число ступенів свободи чисельника для $F$-розподілу, де $[z]$– ціла частина числа $z$.
    \item Стверджуємо, що з ймовірністю $(1-\alpha)\cdot 100\%$ істинне значення кореляційного відношення задовольняє нерівностям
    $$\displaystyle \frac{\left(n-s\right) \hat{\rho}_{yx}^2}{n\left(1- \hat{\rho}_{yx}^2\right)F\left(\displaystyle\frac{\alpha}{2};\nu_{1}^{*};n-s \right)} - \frac{s-1}{n} < \rho_{yx}^2 <\frac{\left(n-s\right)\hat{\rho}_{yx}^2}{n\left(1-\hat{\rho}_{yx}^2\right)F\left(\displaystyle 1-\frac{\alpha}{2};\nu_{1}^{*};n-s \right)} - \frac{s-1}{n} \;\;\;\left(18\right)$$
\end{enumerate}""")

v1 = (s - 1 + 30 * p2)**2 / (s - 1 + 2 * 30 * p2)

print(r"Визначимо $\displaystyle \nu_{1}^{*}$ за формулою (17) при $n=30$,$s="+f"{s}$, $\\hat{{\\rho}}_{{yx}}^2 = {round(p2, 4)}$:")
print(r"$$\\displaystyle \nu_{1}^{*}= \left[\frac{\left(" + f"{s}-1+30 \\cdot {round(p2, 4)} \\right)^2}}{{{s}-1+2\\cdot 30\\cdot {round(p2, 4)}}}\\right]= [{round(v1, 3)}] = {math.trunc(v1)}$$")
print(r"Відповідно до нерівності (18) при $n=30$,$s="+str(s)+r"$, $\alpha=0.1$:")

left_bound = (n - s)*p2/(n*(1-p2)*fishers_f.isf(0.05, v1, n-s)) - (s-1)/n
right_bound = (n - s)*p2/(n*(1-p2)*fishers_f.isf(1 - 0.05, v1, n-s)) - (s-1)/n

print(r"$$\displaystyle \frac{"+f"{n-s}"+r"\cdot "+f"{round(p2, 4)}"+r"}{30\left(1- "+f"{round(p2, 4)}"+r"\right)F\left(\displaystyle\frac{0.1}{2};"+f"{math.trunc(v1)}"+r";"+f"{n-s}"+r" \right)} - \frac{"+f"{s-1}"+r"}{30} < \rho_{yx}^2 <\frac{"+f"{n-s}"+r" \cdot "+f"{round(p2, 4)}"+r"}{30\left(1 - "+f"{round(p2, 4)}"+r"\right)F\left(\displaystyle 1-\frac{0.1}{2};"+f"{math.trunc(v1)}"+r";"+f"{n-s}"+r" \right)} - \frac{"+f"{s-1}"+r"}{30}$$")
print(f"$${round(left_bound,5)}  < \\rho_{{yx}}^2 < {round(right_bound,5)}$$")
if left_bound < 0:
    print(f"Так як $p \\in [0;1]$, то отримаємо $0  \\leq  \\rho_{{yx}} < {round(right_bound,5)}$")
    left_bound = 0


print(r"""\newline
\newline
Отримали, що з ймовірністю 90\% істине значення значення кореляційного відношення належить проміжку $"""+f"[{round(left_bound,5)};{round(right_bound,5)})"+r""",$ тобто $p \in """+f"[{round(left_bound,5)};{round(right_bound,5)})"+r"""$
Ми можемо зробити висновок про відсутність залежності між продуктивнiстю працi і фондовіддачею. 
\newpage""")