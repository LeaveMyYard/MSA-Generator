
print(r"""\section{Завдання №2}
Для вибірки із завдання 1. \\
1. Розрахувати лінійний парний коефіцієнт кореляції, перевірити його значущість та знайти інтервал довіри. \\
2. Що можна сказати про тісноту та напрямок зв’язку між ознаками? \\
3. За тими ж даними розрахувати кореляційне відношення, перевірити його значущість та знайти інтервали довіри. \\
4. Порівняти значення коефіцієнта детермінації (див. завдання 1), коефіцієнта кореляції та кореляційного відношення. Надати змістовну інтерпретацію отриманим результатам. Чи можна вважати зв’язок між ознаками близьким до лінійного? 
\subsection{Розв'язання}
\textbf{Лінійний коефіцієнт кореляції.}
\subsubsection{Лінійний парний коефіцієнт кореляції.}
Одним із основних показників взаємозалежності двох випадкових величин є парний коефіцієнт кореляції. Його вперше розглянули Пірсон, Еджворт і Велтон.\\
Парний коефіцієнт кореляції характеризує тісноту і напрямок зв’язку між двома корелюючими ознаками у випадку наявності між ними лінійної залежності.\\
Ці дві ознаки повинні вести себе як двовимірна нормальна випадкова величина.\\
Відзначимо властивості парного коефіцієнта кореляції.
1. Значення коефіцієнта кореляції належить відрізкові [-1; 1]. Якщо $\widehat{r}>0$ , то зв’язок між ознаками x і y прямий (обидві зростають або обидві зменшуються одночасно); якщо ж $\widehat{r}<0$, то зв’язок обернений (якщо одна ознака зростає, то друга спадає і навпаки).\\
2. Якщо випадкові величини x і y статистично незалежні, то $\widehat{r}=0$\\
3. Із того, що $\widehat{r}=0$, випливає лінійна незалежність випадкових величин.\\
4. Якщо $\widehat{r}=1$, то це означає, що між змінними x і y існує функціональний лінійний зв’язок і навпаки: якщо між x і y існує функціональна лінійна залежність, то $\widehat{r}=1$.\\
5. Коефіцієнт кореляції є симетричною функцією змінних x і y : $\widehat{r_{xy}}=\widehat{r_{yx}}$. \\
Визначений співвідношенням (1) вибірковий коефіцієнт кореляції може бути розрахований для довільної двовимірної системи спостережень. Він є вимірником ступеня тісноти лінійного статистичного зв’язку між ознаками. Однак
тільки у випадку спільного нормального розподілу випадкових величин коефіцієнт кореляції r має чітке значення як характеристика ступеня тісноти зв’язку між ними.\\
Крім того, коефіцієнт кореляції разом з середніми і дисперсіями випадкових величин складає ті п’ять параметрів, які дають вичерпні відомості про стохастичну залежність величин, тому що однозначно визначають їх двовимірний закон розподілу.\\
У всіх інших випадках (розподіли x і y відхиляються від нормального, одна з величин не є випадковою і т. д.) коефіцієнт кореляції можна використовувати лише як одну з можливих характеристик ступеня тісноти зв’язку. При цьому, не дивлячись на те, що в загальному випадку поки що не запропоновано характеристики лінійного зв’язку, яка мала б очевидні переваги в порівнянні з r ,його інтерпретація досить часто є ненадійною. Якщо апріорі допускається можливість відхилення від лінійного вигляду залежності, то можна побудувати приклади, коли при r = 0 існує чисто функціональна залежність між ознаками. Тому про величини, для яких r = 0 , кажуть, що вони некорельовані, і тільки після професійного аналізу можна сказати, чи є вони незалежними. І навпаки, з
високого ступеня корельованості величин при великих відхиленнях їх розподілів від нормального ще не виходить їх досить тісна залежність.\\ 
 Використовуючи вибіркові дані прикладу 1, розрахувати парний коефіцієнт кореляції за формулою:\\
\\
$$\displaystyle \hat{r}= \frac{\displaystyle n\sum_{i=1}^{n}x_{i}y_{i}-\sum_{i=1}^{n}x_{i}  \cdot \sum_{i=1}^{n}y_{i}}{\displaystyle \sqrt{\left[n\sum_{i=1}^{n}x^2_{i}- \left(\sum_{i=1}^{n}x_{i} \right )^{2} \right ] \cdot
\left[n\sum_{i=1}^{n}y^2_{i}- \left(\sum_{i=1}^{n}y_{i} \right )^{2} \right ] }}   \;\;\;(7)$$
Відпвідно до формули (7):""")